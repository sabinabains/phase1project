{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project Submission\n",
    "\n",
    "Please fill out:\n",
    "* Student name: Sabina Bains\n",
    "* Student pace: self paced\n",
    "* Scheduled project review date/time: \n",
    "* Instructor name: Claude Fried\n",
    "* Blog post URL: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Standard Packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "imdb variable explanation: https://www.imdb.com/interfaces/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['zippeddata/imdb.title.crew.csv.gz',\n",
       " 'zippeddata/imdb.title.basics.tsv.gz',\n",
       " 'zippeddata/tmdb.movies.csv.gz',\n",
       " 'zippeddata/imdb.title.akas.csv.gz',\n",
       " 'zippeddata/imdb.title.ratings.csv.gz',\n",
       " 'zippeddata/imdb.name.basics.csv.gz',\n",
       " 'zippeddata/rt.reviews.tsv.gz',\n",
       " 'zippeddata/imdb.title.basics.csv.gz',\n",
       " 'zippeddata/rt.movie_info.tsv.gz',\n",
       " 'zippeddata/tn.movie_budgets.csv.gz',\n",
       " 'zippeddata/bom.movie_gross.csv.gz',\n",
       " 'zippeddata/imdb.title.principals.csv.gz']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Viewing and changing filenames for easier file importing\n",
    "\n",
    "filenames = os.listdir('/Users/sabinabains/Desktop/dsci/Phase1/Phase1Project/dsc-phase-1-project/zippedData')\n",
    "fullname = []\n",
    "\n",
    "for file in filenames:\n",
    "    fullname.append('zippeddata/'+file)\n",
    "    \n",
    "fullname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to describe each data set\n",
    "\n",
    "def df_summary(df,list_num):\n",
    "    print('''This dataset is called {}\n",
    "It has {} rows\n",
    "and {} duplicates\n",
    "\n",
    "Columns present and N/A values are:\n",
    "{}\n",
    "\n",
    "Description:\n",
    "{}\n",
    "\n",
    "Data Preview:\n",
    "{}\n",
    "    '''.format(fullname[list_num][11:][:-7],len(df),len(df[df.duplicated()]),df.isna().sum(),df.describe(),df.head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset is called imdb.title.crew\n",
      "It has 146144 rows\n",
      "and 0 duplicates\n",
      "\n",
      "Columns present and N/A values are:\n",
      "tconst           0\n",
      "directors     5727\n",
      "writers      35883\n",
      "dtype: int64\n",
      "\n",
      "Description:\n",
      "           tconst  directors    writers\n",
      "count      146144     140417     110261\n",
      "unique     146144      98525      91920\n",
      "top     tt1996226  nm3266654  nm0000636\n",
      "freq            1         62         80\n",
      "\n",
      "Data Preview:\n",
      "      tconst                      directors              writers\n",
      "0  tt0285252                      nm0899854            nm0899854\n",
      "1  tt0438973                            NaN  nm0175726,nm1802864\n",
      "2  tt0462036                      nm1940585            nm1940585\n",
      "3  tt0835418                      nm0151540  nm0310087,nm0841532\n",
      "4  tt0878654  nm0089502,nm2291498,nm2292011            nm0284943\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "imdb_crew = pd.read_csv(fullname[0])\n",
    "df_summary(imdb_crew,0)\n",
    "\n",
    "# print('''This dataset has a lot of NA columns, especially for the writers. Not sure how valuable this data will be yet.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset is called tmdb.movies\n",
      "It has 26517 rows\n",
      "and 0 duplicates\n",
      "\n",
      "Columns present and N/A values are:\n",
      "Unnamed: 0           0\n",
      "genre_ids            0\n",
      "id                   0\n",
      "original_language    0\n",
      "original_title       0\n",
      "popularity           0\n",
      "release_date         0\n",
      "title                0\n",
      "vote_average         0\n",
      "vote_count           0\n",
      "dtype: int64\n",
      "\n",
      "Description:\n",
      "        Unnamed: 0             id    popularity  vote_average    vote_count\n",
      "count  26517.00000   26517.000000  26517.000000  26517.000000  26517.000000\n",
      "mean   13258.00000  295050.153260      3.130912      5.991281    194.224837\n",
      "std     7654.94288  153661.615648      4.355229      1.852946    960.961095\n",
      "min        0.00000      27.000000      0.600000      0.000000      1.000000\n",
      "25%     6629.00000  157851.000000      0.600000      5.000000      2.000000\n",
      "50%    13258.00000  309581.000000      1.374000      6.000000      5.000000\n",
      "75%    19887.00000  419542.000000      3.694000      7.000000     28.000000\n",
      "max    26516.00000  608444.000000     80.773000     10.000000  22186.000000\n",
      "\n",
      "Data Preview:\n",
      "   Unnamed: 0            genre_ids     id original_language  \\\n",
      "0           0      [12, 14, 10751]  12444                en   \n",
      "1           1  [14, 12, 16, 10751]  10191                en   \n",
      "2           2        [12, 28, 878]  10138                en   \n",
      "3           3      [16, 35, 10751]    862                en   \n",
      "4           4        [28, 878, 12]  27205                en   \n",
      "\n",
      "                                 original_title  popularity release_date  \\\n",
      "0  Harry Potter and the Deathly Hallows: Part 1      33.533   2010-11-19   \n",
      "1                      How to Train Your Dragon      28.734   2010-03-26   \n",
      "2                                    Iron Man 2      28.515   2010-05-07   \n",
      "3                                     Toy Story      28.005   1995-11-22   \n",
      "4                                     Inception      27.920   2010-07-16   \n",
      "\n",
      "                                          title  vote_average  vote_count  \n",
      "0  Harry Potter and the Deathly Hallows: Part 1           7.7       10788  \n",
      "1                      How to Train Your Dragon           7.7        7610  \n",
      "2                                    Iron Man 2           6.8       12368  \n",
      "3                                     Toy Story           7.9       10174  \n",
      "4                                     Inception           8.3       22186  \n",
      "    \n",
      "The Movie Database - has an API. This dataset looks valuable. it has no missing data and popularity / votes for each movie.\n",
      "Also has a genre ID, can we map it to something to answer the business question?\n"
     ]
    }
   ],
   "source": [
    "movies = pd.read_csv(fullname[2])\n",
    "df_summary(movies,2)\n",
    "\n",
    "\n",
    "print(\"\"\"The Movie Database - has an API. This dataset looks valuable. it has no missing data and popularity / votes for each movie.\n",
    "Also has a genre ID, can we map it to something to answer the business question?\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset is called imdb.title.akas\n",
      "It has 331703 rows\n",
      "and 0 duplicates\n",
      "\n",
      "Columns present and N/A values are:\n",
      "title_id                  0\n",
      "ordering                  0\n",
      "title                     0\n",
      "region                53293\n",
      "language             289988\n",
      "types                163256\n",
      "attributes           316778\n",
      "is_original_title        25\n",
      "dtype: int64\n",
      "\n",
      "Description:\n",
      "            ordering  is_original_title\n",
      "count  331703.000000      331678.000000\n",
      "mean        5.125872           0.134769\n",
      "std         6.706664           0.341477\n",
      "min         1.000000           0.000000\n",
      "25%         1.000000           0.000000\n",
      "50%         2.000000           0.000000\n",
      "75%         6.000000           0.000000\n",
      "max        61.000000           1.000000\n",
      "\n",
      "Data Preview:\n",
      "    title_id  ordering                                    title region  \\\n",
      "0  tt0369610        10                            Джурасик свят     BG   \n",
      "1  tt0369610        11                        Jurashikku warudo     JP   \n",
      "2  tt0369610        12  Jurassic World: O Mundo dos Dinossauros     BR   \n",
      "3  tt0369610        13                  O Mundo dos Dinossauros     BR   \n",
      "4  tt0369610        14                           Jurassic World     FR   \n",
      "\n",
      "  language        types   attributes  is_original_title  \n",
      "0       bg          NaN          NaN                0.0  \n",
      "1      NaN  imdbDisplay          NaN                0.0  \n",
      "2      NaN  imdbDisplay          NaN                0.0  \n",
      "3      NaN          NaN  short title                0.0  \n",
      "4      NaN  imdbDisplay          NaN                0.0  \n",
      "    \n",
      "Lots of N/As. Looks like a dataset for whether a title is original or not. Maybe can cross check these\n",
      "at the end of the analysis to exlude anything that isn't original?\n"
     ]
    }
   ],
   "source": [
    "akas = pd.read_csv(fullname[3])\n",
    "df_summary(akas,3)\n",
    "\n",
    "print('''Lots of N/As. Looks like a dataset for whether a title is original or not. Maybe can cross check these\n",
    "at the end of the analysis to exlude anything that isn't original?''')\n",
    "# akas.loc[akas['is_original_title']==1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset is called imdb.title.ratings\n",
      "It has 73856 rows\n",
      "and 0 duplicates\n",
      "\n",
      "Columns present and N/A values are:\n",
      "tconst           0\n",
      "averagerating    0\n",
      "numvotes         0\n",
      "dtype: int64\n",
      "\n",
      "Description:\n",
      "       averagerating      numvotes\n",
      "count   73856.000000  7.385600e+04\n",
      "mean        6.332729  3.523662e+03\n",
      "std         1.474978  3.029402e+04\n",
      "min         1.000000  5.000000e+00\n",
      "25%         5.500000  1.400000e+01\n",
      "50%         6.500000  4.900000e+01\n",
      "75%         7.400000  2.820000e+02\n",
      "max        10.000000  1.841066e+06\n",
      "\n",
      "Data Preview:\n",
      "       tconst  averagerating  numvotes\n",
      "0  tt10356526            8.3        31\n",
      "1  tt10384606            8.9       559\n",
      "2   tt1042974            6.4        20\n",
      "3   tt1043726            4.2     50352\n",
      "4   tt1060240            6.5        21\n",
      "    \n",
      "No N/A values to remove. looks like 'tconst' is a unique title ID that we will need to map.\n",
      "dataset looks useful with 'averagerating' and 'numvotes' \n"
     ]
    }
   ],
   "source": [
    "ratings = pd.read_csv(fullname[3])\n",
    "df_summary(ratings,3)\n",
    "\n",
    "print('''No N/A values to remove. looks like 'tconst' is a unique title ID that we will need to map.\n",
    "dataset looks useful with 'averagerating' and 'numvotes' ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset is called imdb.name.basics\n",
      "It has 606648 rows\n",
      "and 0 duplicates\n",
      "\n",
      "Columns present and N/A values are:\n",
      "nconst                     0\n",
      "primary_name               0\n",
      "birth_year            523912\n",
      "death_year            599865\n",
      "primary_profession     51340\n",
      "known_for_titles       30204\n",
      "dtype: int64\n",
      "\n",
      "Description:\n",
      "         birth_year   death_year\n",
      "count  82736.000000  6783.000000\n",
      "mean    1967.043826  2000.523367\n",
      "std       22.122190    43.951530\n",
      "min        1.000000    17.000000\n",
      "25%     1957.000000  2001.000000\n",
      "50%     1971.000000  2013.000000\n",
      "75%     1981.000000  2016.000000\n",
      "max     2014.000000  2019.000000\n",
      "\n",
      "Data Preview:\n",
      "      nconst       primary_name  birth_year  death_year  \\\n",
      "0  nm0061671  Mary Ellen Bauder         NaN         NaN   \n",
      "1  nm0061865       Joseph Bauer         NaN         NaN   \n",
      "2  nm0062070         Bruce Baum         NaN         NaN   \n",
      "3  nm0062195       Axel Baumann         NaN         NaN   \n",
      "4  nm0062798        Pete Baxter         NaN         NaN   \n",
      "\n",
      "                                 primary_profession  \\\n",
      "0         miscellaneous,production_manager,producer   \n",
      "1        composer,music_department,sound_department   \n",
      "2                        miscellaneous,actor,writer   \n",
      "3  camera_department,cinematographer,art_department   \n",
      "4  production_designer,art_department,set_decorator   \n",
      "\n",
      "                          known_for_titles  \n",
      "0  tt0837562,tt2398241,tt0844471,tt0118553  \n",
      "1  tt0896534,tt6791238,tt0287072,tt1682940  \n",
      "2  tt1470654,tt0363631,tt0104030,tt0102898  \n",
      "3  tt0114371,tt2004304,tt1618448,tt1224387  \n",
      "4  tt0452644,tt0452692,tt3458030,tt2178256  \n",
      "    \n",
      "Birth/Death year doesn't seem to be relevant and have many null columns. \n",
      "Not yet sure how / if we will use this data\n"
     ]
    }
   ],
   "source": [
    "people = pd.read_csv(fullname[4])\n",
    "df_summary(people,4)\n",
    "\n",
    "print('''Birth/Death year doesn't seem to be relevant and have many null columns. \n",
    "Not yet sure how / if we will use this data''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset is called imdb.title.basics\n",
      "It has 146144 rows\n",
      "and 0 duplicates\n",
      "\n",
      "Columns present and N/A values are:\n",
      "tconst                 0\n",
      "primary_title          0\n",
      "original_title        21\n",
      "start_year             0\n",
      "runtime_minutes    31739\n",
      "genres              5408\n",
      "dtype: int64\n",
      "\n",
      "Description:\n",
      "          start_year  runtime_minutes\n",
      "count  146144.000000    114405.000000\n",
      "mean     2014.621798        86.187247\n",
      "std         2.733583       166.360590\n",
      "min      2010.000000         1.000000\n",
      "25%      2012.000000        70.000000\n",
      "50%      2015.000000        87.000000\n",
      "75%      2017.000000        99.000000\n",
      "max      2115.000000     51420.000000\n",
      "\n",
      "Data Preview:\n",
      "      tconst                    primary_title              original_title  \\\n",
      "0  tt0063540                        Sunghursh                   Sunghursh   \n",
      "1  tt0066787  One Day Before the Rainy Season             Ashad Ka Ek Din   \n",
      "2  tt0069049       The Other Side of the Wind  The Other Side of the Wind   \n",
      "3  tt0069204                  Sabse Bada Sukh             Sabse Bada Sukh   \n",
      "4  tt0100275         The Wandering Soap Opera       La Telenovela Errante   \n",
      "\n",
      "   start_year  runtime_minutes                genres  \n",
      "0        2013            175.0    Action,Crime,Drama  \n",
      "1        2019            114.0       Biography,Drama  \n",
      "2        2018            122.0                 Drama  \n",
      "3        2018              NaN          Comedy,Drama  \n",
      "4        2017             80.0  Comedy,Drama,Fantasy  \n",
      "    \n",
      "Can merge this info on later to gather info. Perhaps do something with adult vs. kid movies?\n",
      "runtime and genres have lots of missing data\n"
     ]
    }
   ],
   "source": [
    "titlebasics = pd.read_csv(fullname[6])\n",
    "df_summary(titlebasics,6)\n",
    "\n",
    "print('''Can merge this info on later to gather info. Perhaps do something with adult vs. kid movies?\n",
    "runtime and genres have lots of missing data''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset is called tn.movie_budgets\n",
      "It has 5782 rows\n",
      "and 0 duplicates\n",
      "\n",
      "Columns present and N/A values are:\n",
      "id                   0\n",
      "release_date         0\n",
      "movie                0\n",
      "production_budget    0\n",
      "domestic_gross       0\n",
      "worldwide_gross      0\n",
      "dtype: int64\n",
      "\n",
      "Description:\n",
      "                id\n",
      "count  5782.000000\n",
      "mean     50.372363\n",
      "std      28.821076\n",
      "min       1.000000\n",
      "25%      25.000000\n",
      "50%      50.000000\n",
      "75%      75.000000\n",
      "max     100.000000\n",
      "\n",
      "Data Preview:\n",
      "   id  release_date                                        movie  \\\n",
      "0   1  Dec 18, 2009                                       Avatar   \n",
      "1   2  May 20, 2011  Pirates of the Caribbean: On Stranger Tides   \n",
      "2   3   Jun 7, 2019                                 Dark Phoenix   \n",
      "3   4   May 1, 2015                      Avengers: Age of Ultron   \n",
      "4   5  Dec 15, 2017            Star Wars Ep. VIII: The Last Jedi   \n",
      "\n",
      "  production_budget domestic_gross worldwide_gross  \n",
      "0      $425,000,000   $760,507,625  $2,776,345,279  \n",
      "1      $410,600,000   $241,063,875  $1,045,663,875  \n",
      "2      $350,000,000    $42,762,350    $149,762,350  \n",
      "3      $330,600,000   $459,005,868  $1,403,013,963  \n",
      "4      $317,000,000   $620,181,382  $1,316,721,747  \n",
      "    \n",
      " no missing data! but has limited rows compared to other dfs. shows sales & budget info.\n"
     ]
    }
   ],
   "source": [
    "budgets = pd.read_csv(fullname[8])\n",
    "df_summary(budgets,8)\n",
    "\n",
    "print(''' no missing data! but has limited rows compared to other dfs. shows sales & budget info.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset is called bom.movie_gross\n",
      "It has 3387 rows\n",
      "and 0 duplicates\n",
      "\n",
      "Columns present and N/A values are:\n",
      "title                0\n",
      "studio               5\n",
      "domestic_gross      28\n",
      "foreign_gross     1350\n",
      "year                 0\n",
      "dtype: int64\n",
      "\n",
      "Description:\n",
      "       domestic_gross         year\n",
      "count    3.359000e+03  3387.000000\n",
      "mean     2.874585e+07  2013.958075\n",
      "std      6.698250e+07     2.478141\n",
      "min      1.000000e+02  2010.000000\n",
      "25%      1.200000e+05  2012.000000\n",
      "50%      1.400000e+06  2014.000000\n",
      "75%      2.790000e+07  2016.000000\n",
      "max      9.367000e+08  2018.000000\n",
      "\n",
      "Data Preview:\n",
      "                                         title studio  domestic_gross  \\\n",
      "0                                  Toy Story 3     BV     415000000.0   \n",
      "1                   Alice in Wonderland (2010)     BV     334200000.0   \n",
      "2  Harry Potter and the Deathly Hallows Part 1     WB     296000000.0   \n",
      "3                                    Inception     WB     292600000.0   \n",
      "4                          Shrek Forever After   P/DW     238700000.0   \n",
      "\n",
      "  foreign_gross  year  \n",
      "0     652000000  2010  \n",
      "1     691300000  2010  \n",
      "2     664300000  2010  \n",
      "3     535700000  2010  \n",
      "4     513900000  2010  \n",
      "    \n",
      "foreign gross has many nulls. simple dataset with title and domestic gross. small dataset\n"
     ]
    }
   ],
   "source": [
    "gross = pd.read_csv(fullname[9])\n",
    "df_summary(gross,9)\n",
    "\n",
    "print('''foreign gross has many nulls. simple dataset with title and domestic gross. small dataset''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset is called imdb.title.principals\n",
      "It has 1028186 rows\n",
      "and 0 duplicates\n",
      "\n",
      "Columns present and N/A values are:\n",
      "tconst             0\n",
      "ordering           0\n",
      "nconst             0\n",
      "category           0\n",
      "job           850502\n",
      "characters    634826\n",
      "dtype: int64\n",
      "\n",
      "Description:\n",
      "           ordering\n",
      "count  1.028186e+06\n",
      "mean   4.739847e+00\n",
      "std    2.747446e+00\n",
      "min    1.000000e+00\n",
      "25%    2.000000e+00\n",
      "50%    4.000000e+00\n",
      "75%    7.000000e+00\n",
      "max    1.000000e+01\n",
      "\n",
      "Data Preview:\n",
      "      tconst  ordering     nconst  category       job        characters\n",
      "0  tt0111414         1  nm0246005     actor       NaN       [\"The Man\"]\n",
      "1  tt0111414         2  nm0398271  director       NaN               NaN\n",
      "2  tt0111414         3  nm3739909  producer  producer               NaN\n",
      "3  tt0323808        10  nm0059247    editor       NaN               NaN\n",
      "4  tt0323808         1  nm3579312   actress       NaN  [\"Beth Boothby\"]\n",
      "    \n",
      "missing values for job and characters. ties cast to tconst\n"
     ]
    }
   ],
   "source": [
    "cast = pd.read_csv(fullname[10])\n",
    "df_summary(cast,10)\n",
    "\n",
    "print('''missing values for job and characters. ties cast to tconst''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset is called rt.reviews\n",
      "It has 54432 rows\n",
      "and 9 duplicates\n",
      "\n",
      "Columns present and N/A values are:\n",
      "id                0\n",
      "review         5563\n",
      "rating        13517\n",
      "fresh             0\n",
      "critic         2722\n",
      "top_critic        0\n",
      "publisher       309\n",
      "date              0\n",
      "dtype: int64\n",
      "\n",
      "Description:\n",
      "                 id    top_critic\n",
      "count  54432.000000  54432.000000\n",
      "mean    1045.706882      0.240594\n",
      "std      586.657046      0.427448\n",
      "min        3.000000      0.000000\n",
      "25%      542.000000      0.000000\n",
      "50%     1083.000000      0.000000\n",
      "75%     1541.000000      0.000000\n",
      "max     2000.000000      1.000000\n",
      "\n",
      "Data Preview:\n",
      "   id                                             review rating   fresh  \\\n",
      "0   3  A distinctly gallows take on contemporary fina...    3/5   fresh   \n",
      "1   3  It's an allegory in search of a meaning that n...    NaN  rotten   \n",
      "2   3  ... life lived in a bubble in financial dealin...    NaN   fresh   \n",
      "3   3  Continuing along a line introduced in last yea...    NaN   fresh   \n",
      "4   3             ... a perverse twist on neorealism...     NaN   fresh   \n",
      "\n",
      "           critic  top_critic         publisher               date  \n",
      "0      PJ Nabarro           0   Patrick Nabarro  November 10, 2018  \n",
      "1  Annalee Newitz           0           io9.com       May 23, 2018  \n",
      "2    Sean Axmaker           0  Stream on Demand    January 4, 2018  \n",
      "3   Daniel Kasman           0              MUBI  November 16, 2017  \n",
      "4             NaN           0      Cinema Scope   October 12, 2017  \n",
      "    \n",
      " need to delete duplicate rows . maybe map this to the genre part to see which genres have the highest views. based on ID \n"
     ]
    }
   ],
   "source": [
    "rt = pd.read_csv(fullname[5],sep=\"\\t\",encoding= 'unicode_escape')\n",
    "df_summary(rt,5)\n",
    "\n",
    "\n",
    "print(''' need to delete duplicate rows . maybe map this to the genre part to see which genres have the highest views. based on ID ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset is called rt.movie_info\n",
      "It has 1560 rows\n",
      "and 0 duplicates\n",
      "\n",
      "Columns present and N/A values are:\n",
      "id                 0\n",
      "synopsis          62\n",
      "rating             3\n",
      "genre              8\n",
      "director         199\n",
      "writer           449\n",
      "theater_date     359\n",
      "dvd_date         359\n",
      "currency        1220\n",
      "box_office      1220\n",
      "runtime           30\n",
      "studio          1066\n",
      "dtype: int64\n",
      "\n",
      "Description:\n",
      "                id\n",
      "count  1560.000000\n",
      "mean   1007.303846\n",
      "std     579.164527\n",
      "min       1.000000\n",
      "25%     504.750000\n",
      "50%    1007.500000\n",
      "75%    1503.250000\n",
      "max    2000.000000\n",
      "\n",
      "Data Preview:\n",
      "   id                                           synopsis rating  \\\n",
      "0   1  This gritty, fast-paced, and innovative police...      R   \n",
      "1   3  New York City, not-too-distant-future: Eric Pa...      R   \n",
      "2   5  Illeana Douglas delivers a superb performance ...      R   \n",
      "3   6  Michael Douglas runs afoul of a treacherous su...      R   \n",
      "4   7                                                NaN     NR   \n",
      "\n",
      "                                 genre          director  \\\n",
      "0  Action and Adventure|Classics|Drama  William Friedkin   \n",
      "1    Drama|Science Fiction and Fantasy  David Cronenberg   \n",
      "2    Drama|Musical and Performing Arts    Allison Anders   \n",
      "3           Drama|Mystery and Suspense    Barry Levinson   \n",
      "4                        Drama|Romance    Rodney Bennett   \n",
      "\n",
      "                            writer  theater_date      dvd_date currency  \\\n",
      "0                   Ernest Tidyman   Oct 9, 1971  Sep 25, 2001      NaN   \n",
      "1     David Cronenberg|Don DeLillo  Aug 17, 2012   Jan 1, 2013        $   \n",
      "2                   Allison Anders  Sep 13, 1996  Apr 18, 2000      NaN   \n",
      "3  Paul Attanasio|Michael Crichton   Dec 9, 1994  Aug 27, 1997      NaN   \n",
      "4                     Giles Cooper           NaN           NaN      NaN   \n",
      "\n",
      "  box_office      runtime             studio  \n",
      "0        NaN  104 minutes                NaN  \n",
      "1    600,000  108 minutes  Entertainment One  \n",
      "2        NaN  116 minutes                NaN  \n",
      "3        NaN  128 minutes                NaN  \n",
      "4        NaN  200 minutes                NaN  \n",
      "    \n",
      "I don't understand how to tie these to the movie title? but it does have genre info.\n",
      "lots of nulls\n"
     ]
    }
   ],
   "source": [
    "rts = pd.read_csv(fullname[7],sep=\"\\t\",encoding= 'unicode_escape')\n",
    "df_summary(rts,7)\n",
    "\n",
    "print('''I don't understand how to tie these to the movie title? but it does have genre info.\n",
    "lots of nulls''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA CLEANING PROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'nconst'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-5b957e559326>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tconst'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'outer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitlebasics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tconst'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'outer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mimdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpeople\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nconst'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'outer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mimdb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimdb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0makas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'tconst'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'outer'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m ) -> \"DataFrame\":\n\u001b[0;32m---> 74\u001b[0;31m     op = _MergeOperation(\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    650\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1016\u001b[0m                         \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mlk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1018\u001b[0;31m                         \u001b[0mleft_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1019\u001b[0m                         \u001b[0mjoin_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1020\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1561\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1562\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1563\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'nconst'"
     ]
    }
   ],
   "source": [
    "# Merging all IMDB Files \n",
    "imdb_movies = pd.merge(ratings, imdb_crew , on='tconst',how = 'outer')\n",
    "imdb = pd.merge(imdb, cast, on='tconst', how = 'outer')\n",
    "imdb = pd.merge(imdb, titlebasics, on='tconst', how='outer')\n",
    "imdb = pd.merge(imdb, people, on='nconst', how='outer')\n",
    "imdb = pd.merge(imdb, akas, on='tconst', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tconst           0\n",
       "averagerating    0\n",
       "numvotes         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-07c742aa5e6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mratings_dropcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'nconst'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'directors'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'writers'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ordering'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'job'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'characters'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'birth_year'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'death_year'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mratings_dropcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mratings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2912\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2914\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_take_with_is_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_single_key\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_take_with_is_copy\u001b[0;34m(self, indices, axis)\u001b[0m\n\u001b[1;32m   3361\u001b[0m         \u001b[0mSee\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdocstring\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfull\u001b[0m \u001b[0mexplanation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3362\u001b[0m         \"\"\"\n\u001b[0;32m-> 3363\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m         \u001b[0;31m# Maybe set copy if we didn't actually change the index.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[1;32m   3348\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3350\u001b[0;31m         new_data = self._mgr.take(\n\u001b[0m\u001b[1;32m   3351\u001b[0m             \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_block_manager_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3352\u001b[0m         )\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mtake\u001b[0;34m(self, indexer, axis, verify, convert)\u001b[0m\n\u001b[1;32m   1445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1446\u001b[0m         \u001b[0mnew_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1447\u001b[0;31m         return self.reindex_indexer(\n\u001b[0m\u001b[1;32m   1448\u001b[0m             \u001b[0mnew_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnew_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_dups\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1449\u001b[0m         )\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mreindex_indexer\u001b[0;34m(self, new_axis, indexer, axis, fill_value, allow_dups, copy, consolidate)\u001b[0m\n\u001b[1;32m   1280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1282\u001b[0;31m             \u001b[0mnew_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slice_take_blocks_ax0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1283\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m             new_blocks = [\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36m_slice_take_blocks_ax0\u001b[0;34m(self, slice_or_indexer, fill_value, only_slice)\u001b[0m\n\u001b[1;32m   1408\u001b[0m                             \u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1410\u001b[0;31m                         \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtaker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_mgr_locs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1411\u001b[0m                         \u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(self, indexer, axis, new_mgr_locs, fill_value)\u001b[0m\n\u001b[1;32m   1253\u001b[0m             \u001b[0mallow_fill\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1255\u001b[0;31m         new_values = algos.take_nd(\n\u001b[0m\u001b[1;32m   1256\u001b[0m             \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_fill\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_fill\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m         )\n",
      "\u001b[0;32m/opt/anaconda3/envs/learn-env/lib/python3.8/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, out, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m   1711\u001b[0m         \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1712\u001b[0m     )\n\u001b[0;32m-> 1713\u001b[0;31m     \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mflip_order\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# imdb['death_year'].dropna()\n",
    "\n",
    "# df['Fare'].fillna(df['Fare'].median())\n",
    "\n",
    "ratings = imdb.loc[~imdb['averagerating'].isnull()]\n",
    "ratings_dropcols = ['nconst','directors','writers','ordering','job','characters','birth_year','death_year']\n",
    "cols = [col for col in ratings.columns if col not in ratings_dropcols]\n",
    "ratings = ratings[cols]\n",
    "ratings.isna().sum()\n",
    "\n",
    "len(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>averagerating</th>\n",
       "      <th>numvotes</th>\n",
       "      <th>start_year</th>\n",
       "      <th>runtime_minutes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>genres</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Comedy,Documentary,Fantasy</th>\n",
       "      <td>9.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Documentary,Family,Musical</th>\n",
       "      <td>9.3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>History,Sport</th>\n",
       "      <td>9.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Music,Mystery</th>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Game-Show</th>\n",
       "      <td>9.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Crime,Music</th>\n",
       "      <td>2.4</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>History,Sci-Fi,Thriller</th>\n",
       "      <td>2.3</td>\n",
       "      <td>227.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adventure,Crime,Romance</th>\n",
       "      <td>2.3</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2011.0</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adult,Horror</th>\n",
       "      <td>2.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Comedy,Musical,Sport</th>\n",
       "      <td>1.4</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>923 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            averagerating  numvotes  start_year  \\\n",
       "genres                                                            \n",
       "Comedy,Documentary,Fantasy            9.4       5.0      2015.0   \n",
       "Documentary,Family,Musical            9.3      19.0      2017.0   \n",
       "History,Sport                         9.2       5.0      2016.0   \n",
       "Music,Mystery                         9.0       5.0      2012.0   \n",
       "Game-Show                             9.0       7.0      2013.0   \n",
       "...                                   ...       ...         ...   \n",
       "Crime,Music                           2.4      88.0      2018.0   \n",
       "History,Sci-Fi,Thriller               2.3     227.0      2017.0   \n",
       "Adventure,Crime,Romance               2.3       9.0      2011.0   \n",
       "Adult,Horror                          2.0     128.0      2015.0   \n",
       "Comedy,Musical,Sport                  1.4      28.0      2015.0   \n",
       "\n",
       "                            runtime_minutes  \n",
       "genres                                       \n",
       "Comedy,Documentary,Fantasy             70.0  \n",
       "Documentary,Family,Musical             59.0  \n",
       "History,Sport                           NaN  \n",
       "Music,Mystery                           NaN  \n",
       "Game-Show                             130.0  \n",
       "...                                     ...  \n",
       "Crime,Music                            94.0  \n",
       "History,Sci-Fi,Thriller               120.0  \n",
       "Adventure,Crime,Romance                86.0  \n",
       "Adult,Horror                          120.0  \n",
       "Comedy,Musical,Sport                  101.0  \n",
       "\n",
       "[923 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eventually use this\n",
    "# pd.plotting.scatter_matrix(df, figsize=(10,10));\n",
    "genres = ratings.groupby(ratings['genres']).mean()\n",
    "genres = genres.sort_values(by='averagerating', ascending=False)\n",
    "genres.isna().sum()\n",
    "\n",
    "\n",
    "genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTES\n",
    "\n",
    "- look at directors that are most successful for hiring for original movie. break out 'known for' titles\n",
    "- look at genres with highest average rating. split genres?\n",
    "- biggest profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings['genres'] = ratings['genres'].fillna('Unknown')\n",
    "\n",
    "genres = pd.DataFrame()\n",
    "genres = pd.concat([ratings,ratings.genres.str.get_dummies(sep=',')],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tconst</th>\n",
       "      <th>averagerating</th>\n",
       "      <th>numvotes</th>\n",
       "      <th>category</th>\n",
       "      <th>primary_title</th>\n",
       "      <th>original_title</th>\n",
       "      <th>start_year</th>\n",
       "      <th>runtime_minutes</th>\n",
       "      <th>genres</th>\n",
       "      <th>primary_name</th>\n",
       "      <th>...</th>\n",
       "      <th>News</th>\n",
       "      <th>Reality-TV</th>\n",
       "      <th>Romance</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>Short</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>War</th>\n",
       "      <th>Western</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tt10356526</td>\n",
       "      <td>8.3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>production_designer</td>\n",
       "      <td>Laiye Je Yaarian</td>\n",
       "      <td>Laiye Je Yaarian</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>Romance</td>\n",
       "      <td>Kazi Rafik Ali</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tt9190740</td>\n",
       "      <td>8.3</td>\n",
       "      <td>39.0</td>\n",
       "      <td>production_designer</td>\n",
       "      <td>Bhajjo Veero Ve</td>\n",
       "      <td>Bhajjo Veero Ve</td>\n",
       "      <td>2018.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>Comedy,Drama,Romance</td>\n",
       "      <td>Kazi Rafik Ali</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tt10356526</td>\n",
       "      <td>8.3</td>\n",
       "      <td>31.0</td>\n",
       "      <td>actor</td>\n",
       "      <td>Laiye Je Yaarian</td>\n",
       "      <td>Laiye Je Yaarian</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>Romance</td>\n",
       "      <td>Harish Verma</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tt7140020</td>\n",
       "      <td>6.4</td>\n",
       "      <td>24.0</td>\n",
       "      <td>actor</td>\n",
       "      <td>Thug Life</td>\n",
       "      <td>Thug Life</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>Harish Verma</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tt2832540</td>\n",
       "      <td>6.4</td>\n",
       "      <td>268.0</td>\n",
       "      <td>actor</td>\n",
       "      <td>Daddy Cool Munde Fool</td>\n",
       "      <td>Daddy Cool Munde Fool</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Comedy,Romance</td>\n",
       "      <td>Harish Verma</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751618</th>\n",
       "      <td>tt9886934</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>self</td>\n",
       "      <td>The Projectionist</td>\n",
       "      <td>The Projectionist</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>Documentary</td>\n",
       "      <td>Nicolas Nicolaou</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751619</th>\n",
       "      <td>tt9894098</td>\n",
       "      <td>6.3</td>\n",
       "      <td>128.0</td>\n",
       "      <td>actress</td>\n",
       "      <td>Sathru</td>\n",
       "      <td>Sathru</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>Neelima</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751620</th>\n",
       "      <td>tt9894098</td>\n",
       "      <td>6.3</td>\n",
       "      <td>128.0</td>\n",
       "      <td>director</td>\n",
       "      <td>Sathru</td>\n",
       "      <td>Sathru</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>Naveen Nanjundan</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751621</th>\n",
       "      <td>tt9894098</td>\n",
       "      <td>6.3</td>\n",
       "      <td>128.0</td>\n",
       "      <td>composer</td>\n",
       "      <td>Sathru</td>\n",
       "      <td>Sathru</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>Amrish</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>751622</th>\n",
       "      <td>tt9894098</td>\n",
       "      <td>6.3</td>\n",
       "      <td>128.0</td>\n",
       "      <td>editor</td>\n",
       "      <td>Sathru</td>\n",
       "      <td>Sathru</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>Thriller</td>\n",
       "      <td>Prasanna</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>629926 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            tconst  averagerating  numvotes             category  \\\n",
       "0       tt10356526            8.3      31.0  production_designer   \n",
       "1        tt9190740            8.3      39.0  production_designer   \n",
       "3       tt10356526            8.3      31.0                actor   \n",
       "4        tt7140020            6.4      24.0                actor   \n",
       "5        tt2832540            6.4     268.0                actor   \n",
       "...            ...            ...       ...                  ...   \n",
       "751618   tt9886934            7.0       5.0                 self   \n",
       "751619   tt9894098            6.3     128.0              actress   \n",
       "751620   tt9894098            6.3     128.0             director   \n",
       "751621   tt9894098            6.3     128.0             composer   \n",
       "751622   tt9894098            6.3     128.0               editor   \n",
       "\n",
       "                primary_title         original_title  start_year  \\\n",
       "0            Laiye Je Yaarian       Laiye Je Yaarian      2019.0   \n",
       "1             Bhajjo Veero Ve        Bhajjo Veero Ve      2018.0   \n",
       "3            Laiye Je Yaarian       Laiye Je Yaarian      2019.0   \n",
       "4                   Thug Life              Thug Life      2017.0   \n",
       "5       Daddy Cool Munde Fool  Daddy Cool Munde Fool      2013.0   \n",
       "...                       ...                    ...         ...   \n",
       "751618      The Projectionist      The Projectionist      2019.0   \n",
       "751619                 Sathru                 Sathru      2019.0   \n",
       "751620                 Sathru                 Sathru      2019.0   \n",
       "751621                 Sathru                 Sathru      2019.0   \n",
       "751622                 Sathru                 Sathru      2019.0   \n",
       "\n",
       "        runtime_minutes                genres      primary_name  ... News  \\\n",
       "0                 117.0               Romance    Kazi Rafik Ali  ...    0   \n",
       "1                 125.0  Comedy,Drama,Romance    Kazi Rafik Ali  ...    0   \n",
       "3                 117.0               Romance      Harish Verma  ...    0   \n",
       "4                   NaN                Comedy      Harish Verma  ...    0   \n",
       "5                   NaN        Comedy,Romance      Harish Verma  ...    0   \n",
       "...                 ...                   ...               ...  ...  ...   \n",
       "751618             81.0           Documentary  Nicolas Nicolaou  ...    0   \n",
       "751619            129.0              Thriller           Neelima  ...    0   \n",
       "751620            129.0              Thriller  Naveen Nanjundan  ...    0   \n",
       "751621            129.0              Thriller            Amrish  ...    0   \n",
       "751622            129.0              Thriller          Prasanna  ...    0   \n",
       "\n",
       "       Reality-TV  Romance  Sci-Fi  Short  Sport  Thriller  Unknown  War  \\\n",
       "0               0        1       0      0      0         0        0    0   \n",
       "1               0        1       0      0      0         0        0    0   \n",
       "3               0        1       0      0      0         0        0    0   \n",
       "4               0        0       0      0      0         0        0    0   \n",
       "5               0        1       0      0      0         0        0    0   \n",
       "...           ...      ...     ...    ...    ...       ...      ...  ...   \n",
       "751618          0        0       0      0      0         0        0    0   \n",
       "751619          0        0       0      0      0         1        0    0   \n",
       "751620          0        0       0      0      0         1        0    0   \n",
       "751621          0        0       0      0      0         1        0    0   \n",
       "751622          0        0       0      0      0         1        0    0   \n",
       "\n",
       "        Western  \n",
       "0             0  \n",
       "1             0  \n",
       "3             0  \n",
       "4             0  \n",
       "5             0  \n",
       "...         ...  \n",
       "751618        0  \n",
       "751619        0  \n",
       "751620        0  \n",
       "751621        0  \n",
       "751622        0  \n",
       "\n",
       "[629926 rows x 39 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# genres.pivot(index='tconst', columns='', values='')\n",
    "genres\n",
    "\n",
    "## remember to remove duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
